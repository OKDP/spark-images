diff --git a/core/src/main/scala/org/apache/spark/deploy/SparkSubmit.scala b/core/src/main/scala/org/apache/spark/deploy/SparkSubmit.scala
index 18d8559..4feec6c 100644
--- a/core/src/main/scala/org/apache/spark/deploy/SparkSubmit.scala
+++ b/core/src/main/scala/org/apache/spark/deploy/SparkSubmit.scala
@@ -390,7 +390,12 @@ private[spark] class SparkSubmit extends Logging {
     args.jars = Option(args.jars).map(resolveGlobPaths(_, hadoopConf)).orNull
     args.files = Option(args.files).map(resolveGlobPaths(_, hadoopConf)).orNull
     args.pyFiles = Option(args.pyFiles).map(resolveGlobPaths(_, hadoopConf)).orNull
-    args.archives = Option(args.archives).map(resolveGlobPaths(_, hadoopConf)).orNull
+    if (!isKubernetesCluster && sparkConf.getBoolean("spark.kubernetes.resolveGlobPathsInSubmit", true)) {
+        args.jars = Option(args.jars).map(resolveGlobPaths(_, hadoopConf)).orNull
+        args.files = Option(args.files).map(resolveGlobPaths(_, hadoopConf)).orNull
+        args.pyFiles = Option(args.pyFiles).map(resolveGlobPaths(_, hadoopConf)).orNull
+        args.archives = Option(args.archives).map(resolveGlobPaths(_, hadoopConf)).orNull
+    }
 
 
     // In client mode, download remote files.
