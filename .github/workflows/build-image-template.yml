
#
# Copyright 2024 tosit.io
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

name: Spark build single image template

on:
  workflow_call:
    inputs:
      image:
        description: The spark image name (ex. spark-base, spark, spark-py, spark-r, etc)
        required: true
        type: string
      spark_version:
        description: Spark version
        required: true
        type: string
      scala_version:
        description: Scala version
        required: true
        type: string
      java_version:
        description: Java version
        required: true
        type: string
      hadoop_version:
        description: Hadoop version
        required: true
        type: string
      python_version:
        description: Python version
        required: true
        type: string
      publish_to_registry:
        description: Wheter to push to the registry
        required: false
        type: string
        default: "false"
      registry:
        description: The container registry 
        required: false
        type: string
      ci_registry:
        description: "The registry used to push ci images"
        required: false
        type: string
        default: "ghcr.io"
      git_latest_release_tag:
        description: The latest remote release tag 
        required: false
        type: string
        default: ""
      runs-on:
        description: GitHub Actions Runner image
        required: true
        type: string

jobs:
  
  build-test-push:
    name: ${{ inputs.image }} (scala-${{ inputs.scala_version }}, java-${{ inputs.java_version }}, python-${{ inputs.python_version }}, hadoop-${{ inputs.hadoop_version }})
    runs-on: ${{ inputs.runs-on }}
    steps:

      ### The publish and periodic rebuilds are based on the latest stable github release tag
      - name: Checkout latest Github Release tag (${{ inputs.git_latest_release_tag }}) ⚡️
        if: inputs.publish_to_registry == 'true'
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.git_latest_release_tag }}
      
      ### The CI is based on the main branch
      - name: Checkout Repo ⚡️
        if: inputs.publish_to_registry == 'false'
        uses: actions/checkout@v4

      ### Common steps between CI and Publish
      - name: Free up disk space 📦
        uses: ./.github/actions/free-disk-space

      - name: Set up QEMU and Docker Buildx 📦
        uses: ./.github/actions/setup-buildx

      - name: Set up CI and official registries 📦
        id: registry-repos
        run:  |
            echo "repo_owner=${GITHUB_REPOSITORY_OWNER@L}" >> $GITHUB_OUTPUT
            echo "ci_repo=${{ inputs.ci_registry }}/${GITHUB_REPOSITORY_OWNER@L}" >> $GITHUB_OUTPUT
            echo "publish_repo=${{ inputs.registry }}/${GITHUB_REPOSITORY_OWNER@L}" >> $GITHUB_OUTPUT
        shell: bash

      - name: Generate image tags 📦
        id: image-tags
        uses: ./.github/actions/spark-image-tag
        with:
          image: ${{ inputs.image }}
          spark_version: ${{ inputs.spark_version}}
          scala_version: ${{ inputs.scala_version }}
          java_version: ${{ inputs.java_version }}
          python_version: ${{ inputs.python_version}}
          ci_repo: ${{ steps.registry-repos.outputs.ci_repo }}
          publish_repo: ${{ steps.registry-repos.outputs.publish_repo }}
          publish_to_registry: ${{ inputs.publish_to_registry }}
          git_tag_name: ${{ inputs.git_latest_release_tag }}

      - name: Login to the CI registry 🔐
        if: inputs.publish_to_registry == 'false'
        uses: docker/login-action@v3
        with:
          registry: ${{ inputs.ci_registry }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

### start patch

      - name: Prepare patch variables
        id: patch_vars
        # if: inputs.image == 'spark' # uncomment at the end        
        run: |
          set -x
          MINOR=$(echo "${{ inputs.spark_version }}" | awk -F. '{print $1"."$2}')
          PATCH_DIR="./spark/spark-${MINOR}"
          POM_PROPS="${PATCH_DIR}/pombump.properties.yml"
          POM_DEPS="${PATCH_DIR}/pombump-deps.yml"
          echo "minor=$MINOR" >> $GITHUB_OUTPUT
          echo "patch_dir=$PATCH_DIR" >> $GITHUB_OUTPUT
          echo "pom_props=$POM_PROPS" >> $GITHUB_OUTPUT
          echo "pom_deps=$POM_DEPS" >> $GITHUB_OUTPUT
        shell: bash

      - name: Read patch
        id: read_patch
        # if: inputs.image == 'spark' # uncomment at the end
        run: |
          set -x        
          yq -o=json '.controls[]' .build/pre-build-patch.yml > controls.json
          MATCH=$(jq -c \
            --arg spark_version "${{ inputs.spark_version }}" \
            --arg python_version "${{ inputs.python_version }}" \
            --arg java_version "${{ inputs.java_version }}" \
            --arg hadoop_version "${{ inputs.hadoop_version }}" \
            'select(.spark_version == $spark_version and .python_version == $python_version and .java_version == $java_version and .hadoop_version == $hadoop_version)' controls.json)
          if [ -z "$MATCH" ]; then
            echo "patch_files=" >> $GITHUB_OUTPUT
          else
            echo "patch_files=$(echo $MATCH | jq -r '.patch_files | join(",")')" >> $GITHUB_OUTPUT
          fi
        shell: bash

      - name: Apply patch
        id: apply_patch      
        if: steps.read_patch.outputs.patch_files != ''
        run: |
          set -x        
          for patch in $(echo "${{ steps.read_patch.outputs.patch_files }}" | tr ',' '\n'); do
            PATCH_PATH="${{ steps.patch_vars.outputs.patch_dir }}/$patch"
            if [[ -f "$PATCH_PATH" ]]; then
              echo "Applying patch $patch"
              patch -p1 "$PATCH_PATH"
            fi
          done
        shell: bash

      - name: Install and Run pombump
        if: steps.read_patch.outputs.patch_files != ''
        run: |
          set -xe  # Exit immediately if any command fails

          export PATH="$HOME/bin:$PATH"
          mkdir -p "$HOME/bin"

          # Get latest tag
          LATEST_TAG=$(git ls-remote --tags https://github.com/chainguard-dev/pombump.git | awk -F/ '{print $3}' | grep '^v' | sort -V | tail -n1)

          # Clone and build pombump
          git clone --depth 1 --branch "$LATEST_TAG" https://github.com/chainguard-dev/pombump.git /tmp/pombump
          cd /tmp/pombump
          go build -o "$HOME/bin/pombump"
          chmod +x "$HOME/bin/pombump"

          echo "Applying pombump for Spark minor version ${{ steps.patch_vars.outputs.minor }}"
          cd "${{ github.workspace }}"
          ls -lrt .
          pombump pom.xml
          # pombump --properties-file "${{ steps.patch_vars.outputs.pom_props }}" --patch-file "${{ steps.patch_vars.outputs.pom_deps }}"
        shell: bash

### end patch

      - name: Build and push to ci registry
        if: inputs.publish_to_registry == 'false'
        uses: docker/build-push-action@v5
        with:
          context: ${{ inputs.image }}
          platforms: linux/amd64,linux/arm64
          push: true
          build-args: |
            SPARK_VERSION=${{ inputs.spark_version}}
            SCALA_VERSION=${{ inputs.scala_version }}
            JAVA_VERSION=${{ inputs.java_version }}
            PYTHON_VERSION=${{ inputs.python_version }}
            HADOOP_VERSION=${{ inputs.hadoop_version }}
            BASE_IMAGE=${{ steps.image-tags.outputs.parent_image }}
          tags: |
            ${{ steps.registry-repos.outputs.ci_repo }}/${{ inputs.image }}:${{ steps.image-tags.outputs.latest_tag }}
          labels: |
            org.opencontainers.image.title="${{ inputs.image }}"
            org.opencontainers.image.version="${{ inputs.spark_version}}"
            org.opencontainers.image.description="Spark image"
            org.opencontainers.image.base.name="${{ steps.image-tags.outputs.parent_image }}"
            org.opencontainers.image.source="https://github.com/${{ github.repository }}"
            org.opencontainers.image.licenses="Apache-2.0"

      ### CI Steps
      # https://github.com/nektos/act/issues/678
      # https://github.com/apache/spark/pull/35830
      - name: Checkout integration tests tag v${{ inputs.spark_version }} (${{ inputs.spark_version}} > 3.3.0) ⚡️
        if: inputs.publish_to_registry == 'false' && !(startsWith(inputs.spark_version, '3.1') || startsWith(inputs.spark_version, '3.2') || startsWith(inputs.spark_version, '3.3.0'))
        id: git-checkout-tag
        run: |
            CHECKOUT_TAG_DIR="$(mktemp -d)/spark"
            git clone https://github.com/apache/spark.git ${CHECKOUT_TAG_DIR}
            cd ${CHECKOUT_TAG_DIR}
            git checkout v${{ inputs.spark_version }}
            echo "checkout_directory=${CHECKOUT_TAG_DIR}" >> $GITHUB_OUTPUT
        shell: bash

      - name: Prepare integration tests env (${{ inputs.spark_version}} > 3.3.0) 📦
        if: inputs.publish_to_registry == 'false'  && !(startsWith(inputs.spark_version, '3.1') || startsWith(inputs.spark_version, '3.2') || startsWith(inputs.spark_version, '3.3.0'))
        uses: ./.github/actions/spark-tests-prepare
        with:
          spark_version: ${{ inputs.spark_version}}
          scala_version: ${{ inputs.scala_version }}
          java_version: ${{ inputs.java_version }}

      - name: Set up Kind integration tests cluster (${{ inputs.spark_version}} > 3.3.0) 📦
        if: inputs.publish_to_registry == 'false'  && !(startsWith(inputs.spark_version, '3.1') || startsWith(inputs.spark_version, '3.2') || startsWith(inputs.spark_version, '3.3.0'))
        uses: ./.github/actions/setup-kind

      - name: Run integration tests (${{ inputs.spark_version}} > 3.3.0) ✅
        if: inputs.publish_to_registry == 'false' && !(startsWith(inputs.spark_version, '3.1') || startsWith(inputs.spark_version, '3.2') || startsWith(inputs.spark_version, '3.3.0'))
        uses: ./.github/actions/spark-tests-run
        with:
          ci-repo: ${{ steps.registry-repos.outputs.ci_repo }}
          image: ${{ inputs.image }}
          image-tag: ${{ steps.image-tags.outputs.latest_tag }}
          scala_version: ${{ inputs.scala_version }}
          git_checkout_tag_dir: ${{ steps.git-checkout-tag.outputs.checkout_directory }}

      ### Publish steps
      ### The publish and periodic rebuilds are based on the latest stable github release tag
      - name: Login into official registry 🔐
        if: inputs.publish_to_registry == 'true'
        uses: docker/login-action@v3
        with:
          registry: ${{ inputs.registry }}
          username: ${{ secrets.REGISTRY_USERNAME }}
          password: ${{ secrets.REGISTRY_ROBOT_TOKEN }}

      - name: Build and push to official registry 📤
        if: inputs.publish_to_registry == 'true'
        uses: docker/build-push-action@v5
        with:
          context: ${{ inputs.image }}
          platforms: linux/amd64,linux/arm64
          push: true
          build-args: |
            SPARK_VERSION=${{ inputs.spark_version}}
            SCALA_VERSION=${{ inputs.scala_version }}
            JAVA_VERSION=${{ inputs.java_version }}
            PYTHON_VERSION=${{ inputs.python_version }}
            HADOOP_VERSION=${{ inputs.hadoop_version }}
            BASE_IMAGE=${{ steps.image-tags.outputs.parent_image }}
          tags: ${{ steps.image-tags.outputs.publish_tags }}
          labels: |
            org.opencontainers.image.title="${{ inputs.image }}"
            org.opencontainers.image.version="${{ inputs.spark_version}}"
            org.opencontainers.image.description="Spark image"
            org.opencontainers.image.base.name="${{ steps.image-tags.outputs.parent_image }}"
            org.opencontainers.image.source="https://github.com/${{ github.repository }}"
            org.opencontainers.image.licenses="Apache-2.0"

